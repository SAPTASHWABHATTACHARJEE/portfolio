<html>
    <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width,initial-scale=1.0">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
      <link rel="stylesheet" href="project.css" type="text/css" />
      <title>Saptashwa</title>
      <link rel="icon" type="image/x-icon" href="favicon.jpg">
    </head>

    <body><center>
      
      <header class="header">
        <a href="#">
          <img src="favicon.jpg" alt="Saptashwa"> 
          <span class="Saptashwa">Saptashwa</span>
          &nbsp;
        </a>
        <nav class="navbar">
            <ul class="navbar-lists" id="myTopnav">
                <li>
                    <i class="fas fa-home"></i>
                        <a class="navbar-link home-link" href="index.html">Home</a>
                </li>
                
                <li>
                    <i class="fas fa-user"></i>
                        <a class="navbar-link about-link" href="about.html">About Me</a>
                </li>
                
                <li>
                    <i class="fas fa-book-reader"></i>
                        <a class="navbar-link service-link" href="education.html">Education</a>
                </li>

                <li>
                    <i class="fas fa-graduation-cap"></i>
                        <a class="navbar-link service-link" href="awards.html">Awards</a>
                </li>

                <li>
                    <i class="fas fa-microscope"></i>
                        <a class="navbar-link service-link" href="project.html">Projects</a>
                </li>
                
                <li>
                    <i class="fas fa-envelope"></i>
                        <a class="navbar-link contact-link" href="contact.html">Contact Me</a>
                </li>
            </ul>
        </nav>
    </header>

    <td id="layout-content">
        <div class="infoblock">
        <div class="blockcontent">
        <h1>Research focus</h1>
        <p>Our research interest lies in <i>computing hardware and VLSI circuits</i> with the foci given to <i>energy-efficiency</i>, <i>artificial intelligence and machine learning</i>, and <i>hardware security</i>. </p>
        </div></div>
        <h1>Algorithm Hardware Co-Design for AI/ML, DSP, Comm</h1>
        <table class="imgtable"><tr><td>
        <img src="Mathieu.png" alt="hehe" width="400px" />&nbsp;</td>
        <td align="left"><p>Create new algorithm and hardware together to minimize resource use for neural networks, deep learning, digital signal processing (DSP), and wireless communication. </p>
        <ul>
        <li><p>Deep learning based channel estimation processor for 5G millimeter-wave communication systems: <a href="https://doi.org/10.1109/TCSI.2021.3117886">TCASI21</a> <br /></p>
        </li>
        <li><p>Sub-microwatt keyword spotting hardware based on depth-separable convolution neural networks: <a href="https://doi.org/10.1109/ISSCC19947.2020.9063000">ISSCC20</a> <br /></p>
        </li>
        <li><p>Memory-efficient neural network architecture search (NAS): <a href="https://arxiv.org/abs/1907.09569">ArXiv19</a>, <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Liu_MemNAS_Memory-Efficient_Neural_Architecture_Search_With_Grow-Trim_Learning_CVPR_2020_paper.html">CVPR20</a> <br /></p>
        </li>
        <li><p>KTAN: Knowledge Transfer Adversarial Network: <a href="https://doi.org/10.1109/IJCNN48605.2020.9207235">IJCNN20</a></p>
        </li>
        <li><p>FPGA based deep learning accelerator: <a href="https://doi.org/10.1109/ISLPED.2019.8824805">ISLPED19</a> <br /></p>
        </li>
        <li><p>High-capacity fingerprint recognition system based on dynamic capacity estimation of associative memory: <a href="https://arxiv.org/abs/1709.05340">Arxiv17</a>, <a href="https://doi.org/10.1109/BIOCAS.2018.8584741">Biocas18</a> <br /></p>
        </li>
        <li><p>Recursive synaptic bit reuse for associative memory: <a href="https://doi.org/10.23919/DATE.2017.7927246">DATE17</a>, <a href="https://doi.org/10.1109/TVLSI.2018.2884250">TVLSI18</a> <br /></p>
        </li>
        <li><p>Recursive binary neural network training model: <a href="https://doi.org/10.1109/TCSI.2019.2895216">TCASI19</a> <br /></p>
        </li>
        <li><p>Nanowatt 96-channel brain-computer-interface processor, <i>Neural Spike Processor</i>, for motor-intention decoding: <a href="https://doi.org/10.23919/DATE.2017.7927138">DATE17</a>, <a href="https://doi.org/10.1109/ESSCIRC.2018.8494273">ESSCIRC18</a> <br /></p>
        </li>
        <li><p>Spike sorter hardware with Bayesian unsupervised learning: <a href="https://doi.org/10.1109/VLSIC.2016.7573468">VLSI16</a> <a href="https://doi.org/10.1109/TVLSI.2019.2910792">TVLSI19</a> <br /></p>
        </li>
        <li><p>Informative screening in unsupervised learning for spike sorting: <a href="https://doi.org/10.1145/2744769.2744779">DAC15</a> <br /></p>
        </li>
        <li><p>Energy- and area-efficient FFT processor: <a href="https://doi.org/10.1109/ISSCC.2011.5746346">ISSCC11</a>, <a href="https://doi.org/10.1109/JSSC.2011.2169311">JSSC12</a>, <a href="https://doi.org/10.1109/ESSCIRC.2017.8094522">ESSCIRC17</a> <br /></p>
        </li>
        </ul>
        </td></tr></table>

        <h1>In-Memory Computing (IMC) SRAM Circuits and Architecture</h1>
        <table class="imgtable"><tr><td>
        <img src="Mathieu.png" alt="hehe" width="400px" />&nbsp;</td>
        <td align="left"><p>Create novel in and near memory computing architecture for SRAM, DRAM, and NVM. Breaking the memory wall in Von Neumann architecture and also bypassing row-by-row memory access toward single-cycle vector-matrix dot product.</p>
        <ul>
        <li><p>DIMC, digital in-memory computing SRAM based on approximate arithmetic: <a href="https://">ISSCC22</a> <br /></p>
        </li>
        <li><p>MBIMC, analog-mixed-signal in-memory computing SRAM supporting multi-bit weights and inputs: <a href="https://">CICC22</a> <br /></p>
        </li>
        <li><p>C3SRAM, in-memory computing SRAM based on the capacitive coupling mechanism: <a href="https://doi.org/10.1109/LSSC.2019.2934831">ESSCIRC19</a>, <a href="https://doi.org/10.1109/JSSC.2020.2992886">JSSC20</a>, <a href="https://doi.org/10.23919/DATE51398.2021.9473973">DATE21</a>, <a href="https://doi.org/10.1109/DAC18074.2021.9586233">DAC21</a>, <a href="https://doi.org/10.1109/MDAT.2021.3139047">DNT21</a> <br /></p>
        </li>
        <li><p>A deep neural network accelerator featuring in-memory computing SRAM: Vesti: <a href="https://doi.org/10.1109/TVLSI.2019.2940649">TVLSI19</a>, <a href="http://">Asiloma19</a>; PIMCA: <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9508673">VLSI21</a> <br /></p>
        </li>
        <li><p>k-nearest neighbor accelerator using in-memory-computing (IMC) SRAM: <a href="https://doi.org/10.1109/ISLPED.2019.8824822">ISLPED19</a> <br /></p>
        </li>
        <li><p>XNOR-SRAM, in-memory computing SRAM based on the resistive computing mechanism, achieving over 400 TOPS/W and 5 TOPS/mm2 for a vector-matrix dot product in a 65-nm CMOS: <a href="https://doi.org/10.1109/VLSIT.2018.8510687">VLSI18</a>, <a href="https://doi.org/10.1145/3299874.3319458">GLSVLSI19</a>, <a href="https://doi.org/10.1109/JSSC.2019.2963616">JSSC19</a> <br /></p>
        </li>
        </ul>
        </td></tr></table>
        </td></tr></table>
  </center></body>
</html>
